---
title: "General Understading of Land Use Change Models"
author: "Isabel Rosa"
date: "27/08/2018"
output: html_document
---

```{r }

# load necessary packages
library(raster)
library(rgdal)

```

## Goal of the exercise
Today you will have to create two maps that simulate future forest cover in Santa Catarina. These will be created assuming a neighboorhood influence of already deforested areas, and using two approaches: 
- one that imposes a pre-determined rate of change
- one that allows the 'model' to estimate how much deforestation will occur
These maps will be used both tomorrow and on wednesday to estimate impacts on biodiversity and ecosystem services in this region. 


## Import landscape from GIS demo (Santa Catarina tree cover from Hansen dataset), with only two land use classes (e.g., forest, non-forest)
Start this exercise by importing the same raster dataset that you used in the GIS tutorial (tree_cover.tif)

```{r }

# read in tree cover raster
tree_cover<-raster("tree_cover.tif")
loss<-raster("loss.tif")

# make sure the NA value is set to 255
NAvalue(tree_cover)<-255
NAvalue(loss)<-255

# convert from tree cover to binary map (1/0) using a simple rule (can vary this rule later)
# more than 20% is a forest (1), otherwise it's non-forest (0) (out t0 map)
#Hint: remember that R considers TRUE as 1 and FALSE as 0
t0_map<-tree_cover > 20

# plot resulting map
plot(t0_map, main = "Forest Map in t0")

```

## Simulating single transition change (e.g., from forest to non-forest)
Firstly, you are going to simulate a single transition, from forest to non-forest. This transition will have a certain probability of occurring, and this probability will vary depending on several factors. To start, it will only depend of how many neighboors of each pixel are already deforested. Then, we will add some layers of complexity to approach a more realistic simulation. 


## Create probability surface based on deforested neighboorhood

```{r }

# use focal tool to calculate the amount of deforested neighboors, then divide by window size (n*n)
# set window size to 5 for now, you can vary it later to assess impact on outcomes
n<-5
forNeib <- focal(t0_map, w=matrix(1,n,n), fun=sum)/(n*n)

# ensure that your highest value corresponds to the pixels where your forest map is 1, i.e. 
# pixels with value 0 in t0_map should still be 0 in forNeib map
probDef<-t0_map*(1-forNeib)

# visualize map
plot(probDef, main = "Deforestation probability")

```


## Imposing a rate of change (demand-driven) or allowing it to be estimated (data-driven)
As you've learned in the morning, we'll also simulate when you have a 'demand' module imposing a rate of change (how many pixels change from forest to non-forest) and selecting the highest probability of change


```{r }

# data-driven
# use random uniform number (runif) to convert from probability to binary (change, no change)
probmap<-raster(ncol=ncol(t0_map), nrow=nrow(t0_map), xmx=extent(t0_map)@xmax, xmn=extent(t0_map)@xmin, ymn=extent(t0_map)@ymin, ymx=extent(t0_map)@ymax)
values(probmap)<-runif(1:ncell(probmap))

# mask areas that we're not interested in and ensure 0 in t0_map is 0 in the prob map
probmap<-mask(probmap,t0_map)
probmap<-t0_map*probmap

# if probDef > than the randon U(0,1) probability than it is converted, otherwise it is not
changemap <- probDef > probmap #deforestation map

# resulting forest cover
newForest<-t0_map
newForest[changemap==1]<-0

par(mfrow=c(1,2))
# plot change map
plot(changemap, main = "Projected Areas to Change From Forest to Non-Forest")
# plot forest map in t1
plot(newForest, main = "Forest Map in t1")

# demand driven
# get the number of pixels that lost forest from the loss map
# get how many 1's you have in the loss tif
N<-table(values(loss))[2]

# now select the highest probability (from probDef) N pixels
# create data frame with cell ID, probability values and initial forest cover (1/0)
ID_prob<-data.frame(ID=1:ncell(probDef), ProbDef=values(probDef), Forest=values(t0_map))
# order the data frame by ascending probability
sort_ID_prob<-ID_prob[order(-ID_prob$ProbDef),]
# convert the Forest value in the first N rows to 0
sort_ID_prob[1:N,3]<-0

# put the dataframe back in the original ID order
rev_ID_prob<-sort_ID_prob[order(sort_ID_prob$ID),]

# create newForest raster based on t0_map
newForest2<-t0_map
# change values for the new Forest values in the dataframe
values(newForest2)<-rev_ID_prob$Forest

par(mfrow=c(1,2))
# plot results
plot(newForest, main = "Forest Map in t1 (data)") # a lot more deforestation projected in this case
plot(newForest2, main = "Forest Map in t1 (demand)") 

```



## Exporting data for cSAR exercise tomorrow
Here you will create a raster that contains the area of tree cover (assuming all cells have the same area, 300 x 300 m),then change the raster resolution to 900 x 900 m, create an ID raster (for visualization) and finally produce a CSV file with the ID and the associated forest area (the inverse, non-forest area) per pixel


```{r }

# Finally, change raster resolution to 900 x 900 m and get forest and non-forest area per pixel in a .csv
# option b, multiply tree cover by 300 x 300 m and get area of forest (1- that will be non-forest)
tree_cover_area_inkm2<-(tree_cover*300*300)/1000000

# aggregate to 900 x 900 m by summing area in each 300 x 300 m pixels
forest_area<-aggregate(tree_cover_area_inkm2, fact=3, fun = sum)

# creat ID raster (important only if you want to map later the values of cSAR outputs)
IDmap<-raster(ncol=ncol(forest_area), nrow=nrow(forest_area), xmx=extent(forest_area)@xmax, xmn=extent(forest_area)@xmin, ymn=extent(forest_area)@ymin, ymx=extent(forest_area)@ymax)
values(IDmap)<-1:ncell(forest_area)

# create csv with area of forest and no forest, assuming all cells have only forest or no forest
cSAR_data<-data.frame(ID=values(IDmap),Forest=values(forest_area),NonForest=81-values(forest_area))
cSAR_data<-na.omit(cSAR_data)
write.csv(cSAR_data,"LandUse4cSAR.csv", row.names = FALSE)

# for your scenarios: multiply binary response by original tree cover (assuming full conversion), then multiply by area of pixel (300 x 300 m) and finally aggregate to 900 x 900 m using the sum

future_forest<-tree_cover*newForest 
# repeat for newForest 2 (demand-driven scenario)
#future_forest<-tree_cover*newForest2

# same as above but using your future forest map (t1 map)
future_forest_area_inkm2<-(future_forest*300*300)/1000000
future_forest_area<-aggregate(future_forest_area_inkm2, fact=3, fun = sum)
cSAR_data<-data.frame(ID=values(IDmap),Forest=values(future_forest_area),NonForest=81-values(future_forest_area))
cSAR_data<-na.omit(cSAR_data)

# make sure to export at least two scenarios: one data-driven and one demand-driven
#write.csv(cSAR_data,"LandUse4cSAR_future_data.csv", row.names = FALSE)
#write.csv(cSAR_data,"LandUse4cSAR_future_demand.csv", row.names = FALSE)


## you should also export the t1 maps in raster format (for Wednesday class)
#writeRaster(newForest, "t1_forest_data.tif")
#writeRaster(newForest2, "t1_forest_demand.tif")

```


## Explore the 'model' further with more simulations
In this block of exercises you will build on what you worked before and perform more simulations:
1) What happens if you vary the forest threshold in the beginning (i.e., tree cover > 40 --> forest)
2) What happens if you vary the window size to create the deforestation neighboors surface?

```{r }
# vary 'forest' threshold
# repeate the above exercises but assuming a stricter value to define a forest
t0_map<-tree_cover > 40
plot(t0_map)

# vary window size to see effect on amount and location of deforestation
# same as above but you vary the window size of the focal statistics function
forNeib <- focal(t0_map, w=matrix(1,15,15), fun=sum)/(15*15)

## use the code from above, or go a step further and create a function to avoid copying code that does the same thing

```


## Ensembling projection to create probability map
Of course, in the example of estimating the rates of change (data-driven) comparing with a single random uniform map doesn't have much meaning, we need lots of simulations to really determine where it's more likely to occur. Run the exercise above accouting for 100 iterations and average the resulting maps to create the final probability. 

```{r }

# 1) create empty raster to store results
s<-raster(ncol=ncol(t0_map), nrow=nrow(t0_map), xmx=extent(t0_map)@xmax, xmn=extent(t0_map)@xmin, ymn=extent(t0_map)@ymin, ymx=extent(t0_map)@ymax)
values(s)<-rep(0,ncell(tree_cover))

# 2) run for N (e.g., 100) iterations and compile new probability map 
N<-100
for(i in 1:N){
  
  # get a new probability map
  probmap<-raster(ncol=ncol(t0_map), nrow=nrow(t0_map), xmx=extent(t0_map)@xmax, xmn=extent(t0_map)@xmin, ymn=extent(t0_map)@ymin, ymx=extent(t0_map)@ymax)
values(probmap)<-runif(1:ncell(probmap))
  
  # mask areas that we're not interested in and ensure 0 in t0_map is 0 in the prob map
  probmap<-mask(probmap,t0_map)
  probmap<-t0_map*probmap
  
  # get new change map (if probDef higher that probmap, then 1; else then 0)
  changemap <- probDef > probmap #deforestation map
  
  # stack it all together
  s <- stack(s, changemap)
}

# 4) compile to get final probability
final_prob<-(sum(s)/N)*100

# 5) plot projected rate of change alongside projected map
par(mfrow=c(1,2))
boxplot(cellStats(s, sum)[-1], main = 'Projected Rate of Change')
plot(final_prob*t0_map, main = 'Ensembled Probability')

#writeRaster(final_prob, "ensemble_probability.tif")

# aggregate to highlight hotspots
focal_prob<-focal(final_prob, w=matrix(1,15,15), fun=mean)
plot(focal_prob*t0_map, main = 'Ensembled Probability')
#writeRaster(final_prob*t0_map, "ensemble_probability_focal.tif")

```



## Real-world model
Note: in a real-world approch to land use change, you'd have time to study the system, collect information on the variables that impact land use change in the region of interest, and then apply a more robust model to determine the probability of conversion. Further, we focused here on a single transition, whereas in reality you'd have a lot of different land use change possibilities competing, i.e. a conversion of forest can lead to either agricultural lands or pasture lands, for example. Here, the idea was to give a general conceptual framework to the implementation of these models. 
